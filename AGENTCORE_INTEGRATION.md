# AgentCore Integration Guide

This guide explains how to integrate the Goal Hijack Evaluator with Amazon Bedrock AgentCore's native evaluation framework for production monitoring.

## Overview

The project includes two evaluation approaches:

1. **Standalone Evaluator** (`goal_hijack_evaluator.py`) - For development and testing
2. **AgentCore Native Evaluator** - For production continuous monitoring

## Phase 2: AgentCore Native Integration

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Production Agent                          â”‚
â”‚                  (AgentCore Runtime)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Observability Data
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CloudWatch / X-Ray Traces                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Sampled Interactions (5-100%)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Goal Hijack Security Evaluator                       â”‚
â”‚         (Custom AgentCore Evaluator)                         â”‚
â”‚                                                              â”‚
â”‚  â€¢ Prompt Injection Detection                                â”‚
â”‚  â€¢ Goal Deviation Analysis                                   â”‚
â”‚  â€¢ Unauthorized Tool Usage                                   â”‚
â”‚  â€¢ Data Exfiltration Detection                               â”‚
â”‚  â€¢ Suspicious Sequence Analysis                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Risk Scores & Findings
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CloudWatch GenAI Observability                       â”‚
â”‚         â€¢ Dashboards                                         â”‚
â”‚         â€¢ Alarms                                             â”‚
â”‚         â€¢ Metrics                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

1. **AgentCore CLI Installed**
   ```bash
   pip install bedrock-agentcore-starter-toolkit
   ```

2. **Agent Deployed with Observability**
   - Your agent must be deployed to AgentCore Runtime
   - Observability must be enabled
   - At least one agent session completed

3. **AWS Credentials Configured**
   ```bash
   aws configure
   ```

## Quick Start

### Step 1: Deploy the Evaluator

Run the automated deployment script:

```bash
python deploy_agentcore_evaluator.py
```

This will:
1. Check prerequisites
2. Create the custom evaluator
3. Optionally test it
4. Optionally set up continuous monitoring

### Step 2: Manual Deployment (Alternative)

If you prefer manual control:

```bash
# Create the evaluator
agentcore eval evaluator create \
  --name "goal_hijack_detector" \
  --config agentcore_goal_hijack_evaluator_config.json \
  --level TRACE \
  --description "ASI01 Goal Hijack Security Evaluator"

# Verify creation
agentcore eval evaluator list
```

### Step 3: Test the Evaluator

```bash
# Test with latest session
agentcore eval run --evaluator goal_hijack_detector

# Test with specific session
agentcore eval run \
  --evaluator goal_hijack_detector \
  --session-id <your-session-id>

# Save results
agentcore eval run \
  --evaluator goal_hijack_detector \
  --output security_evaluation.json
```

### Step 4: Set Up Continuous Monitoring

```bash
# Create online evaluation configuration
agentcore eval online create \
  --name "security_monitoring" \
  --sampling-rate 5.0 \
  --evaluator "goal_hijack_detector" \
  --description "Continuous ASI01 goal hijack detection"

# List configurations
agentcore eval online list

# View configuration details
agentcore eval online get --config-id <config-id>
```

## Configuration Details

### Evaluator Configuration

The evaluator uses Claude 3.5 Sonnet as the judge model with:

- **Model**: `anthropic.claude-3-5-sonnet-20241022-v2:0`
- **Temperature**: 0.0 (deterministic)
- **Max Tokens**: 1000
- **Level**: TRACE (evaluates individual responses)

### Risk Scoring

| Score | Label | Definition |
|-------|-------|------------|
| 0.0 | High Risk | Clear attack detected, immediate action required |
| 0.3 | Medium Risk | Suspicious patterns, requires investigation |
| 0.7 | Low Risk | Minor anomalies, likely benign |
| 1.0 | Safe | No threats detected |

### Detection Capabilities

1. **Prompt Injection**
   - "Ignore previous instructions"
   - Role manipulation attempts
   - System override commands
   - Social engineering patterns

2. **Goal Deviation**
   - Changes to core objectives
   - Missing baseline keywords
   - Unauthorized goal modifications

3. **Unauthorized Tool Usage**
   - Restricted tool access
   - Tools used outside intended purpose
   - Unknown tool invocations

4. **Data Exfiltration**
   - External recipient detection
   - Bulk data retrieval patterns
   - Unauthorized data transmission

5. **Suspicious Sequences**
   - Data retrieval â†’ external send
   - Privilege escalation patterns
   - Anomalous tool call chains

## Sampling Strategy

### Development/Testing
```bash
# Evaluate 100% of interactions
agentcore eval online create \
  --name "dev_security" \
  --sampling-rate 100.0 \
  --evaluator "goal_hijack_detector"
```

### Production (Low Traffic)
```bash
# Evaluate 10-20% of interactions
agentcore eval online create \
  --name "prod_security" \
  --sampling-rate 10.0 \
  --evaluator "goal_hijack_detector"
```

### Production (High Traffic)
```bash
# Evaluate 1-5% of interactions
agentcore eval online create \
  --name "prod_security" \
  --sampling-rate 1.0 \
  --evaluator "goal_hijack_detector"
```

## Monitoring and Alerting

### View Results in CloudWatch

1. Open [CloudWatch Console](https://console.aws.amazon.com/cloudwatch/)
2. Navigate to **GenAI Observability** â†’ **Bedrock AgentCore**
3. Select your agent
4. View the **Evaluations** tab

### Set Up CloudWatch Alarms

Create alarms for high-risk detections:

```bash
# Create alarm for risk scores < 0.3 (high risk)
aws cloudwatch put-metric-alarm \
  --alarm-name "GoalHijackHighRisk" \
  --alarm-description "Alert on high-risk goal hijack detections" \
  --metric-name "EvaluationScore" \
  --namespace "AWS/BedrockAgentCore" \
  --statistic "Minimum" \
  --period 300 \
  --evaluation-periods 1 \
  --threshold 0.3 \
  --comparison-operator "LessThanThreshold" \
  --alarm-actions <sns-topic-arn>
```

### Query Evaluation Results

Use CloudWatch Logs Insights:

```sql
fields @timestamp, evaluator, score, label, explanation
| filter evaluator = "goal_hijack_detector"
| filter score < 0.3
| sort @timestamp desc
| limit 100
```

## Management Commands

### Update Sampling Rate

```bash
agentcore eval online update \
  --config-id <config-id> \
  --sampling-rate 10.0
```

### Disable Monitoring Temporarily

```bash
agentcore eval online update \
  --config-id <config-id> \
  --status DISABLED
```

### Re-enable Monitoring

```bash
agentcore eval online update \
  --config-id <config-id> \
  --status ENABLED
```

### Delete Configuration

```bash
agentcore eval online delete \
  --config-id <config-id>
```

### Delete Evaluator

```bash
agentcore eval evaluator delete \
  --name "goal_hijack_detector"
```

## Troubleshooting

### "No spans found for session"

**Cause**: CloudWatch logs haven't populated yet (2-5 minute delay)

**Solution**:
```bash
# Invoke agent
agentcore invoke --input "Hello"

# Wait 2-5 minutes
sleep 300

# Try evaluation again
agentcore eval run --evaluator goal_hijack_detector
```

### "No agent specified"

**Cause**: Agent ID not in configuration file

**Solution**:
```bash
# Find agent ID
agentcore status

# Specify explicitly
agentcore eval run \
  --agent-id <your-agent-id> \
  --evaluator goal_hijack_detector
```

### "Evaluator not found"

**Cause**: Evaluator not created or deleted

**Solution**:
```bash
# List evaluators
agentcore eval evaluator list

# Recreate if needed
python deploy_agentcore_evaluator.py
```

### High False Positive Rate

**Solution**: Adjust the evaluator instructions to be more lenient:

1. Edit `agentcore_goal_hijack_evaluator_config.json`
2. Add context about legitimate operations
3. Update the evaluator:
   ```bash
   agentcore eval evaluator delete --name goal_hijack_detector
   agentcore eval evaluator create \
     --name goal_hijack_detector \
     --config agentcore_goal_hijack_evaluator_config.json \
     --level TRACE
   ```

## Cost Considerations

### Evaluation Costs

- **Model**: Claude 3.5 Sonnet
- **Input**: ~500-1000 tokens per evaluation
- **Output**: ~200-500 tokens per evaluation
- **Cost**: ~$0.003-0.015 per evaluation

### Example Monthly Costs

| Traffic | Sampling | Evaluations/Month | Estimated Cost |
|---------|----------|-------------------|----------------|
| 1,000 interactions | 100% | 1,000 | $3-15 |
| 10,000 interactions | 10% | 1,000 | $3-15 |
| 100,000 interactions | 5% | 5,000 | $15-75 |
| 1M interactions | 1% | 10,000 | $30-150 |

## Best Practices

1. **Start Small**: Begin with 5-10% sampling in production
2. **Monitor Costs**: Track evaluation costs in AWS Cost Explorer
3. **Review Regularly**: Check flagged interactions weekly
4. **Tune Thresholds**: Adjust based on false positive/negative rates
5. **Set Alarms**: Create CloudWatch alarms for high-risk detections
6. **Document Findings**: Keep records of security incidents
7. **Update Patterns**: Add new attack patterns as they emerge
8. **Test Changes**: Use standalone evaluator to test before deploying

## Integration with Existing Workflow

### Development Workflow

```bash
# 1. Test locally with standalone evaluator
python test_goal_hijack_evaluation.py
python test_advanced_attack_scenarios.py

# 2. Analyze results
python analyze_evaluation_results.py

# 3. Deploy to AgentCore
python deploy_agentcore_evaluator.py

# 4. Test in production
agentcore eval run --evaluator goal_hijack_detector
```

### CI/CD Integration

```yaml
# .github/workflows/security-evaluation.yml
name: Security Evaluation

on:
  push:
    branches: [main]

jobs:
  evaluate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Run standalone tests
        run: |
          python test_goal_hijack_evaluation.py
          python test_advanced_attack_scenarios.py
      
      - name: Analyze results
        run: python analyze_evaluation_results.py
      
      - name: Deploy to AgentCore (if tests pass)
        if: success()
        run: python deploy_agentcore_evaluator.py
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
```

## Next Steps

1. âœ… Deploy evaluator to AgentCore
2. âœ… Set up continuous monitoring
3. âœ… Configure CloudWatch alarms
4. ğŸ“Š Monitor results for 1-2 weeks
5. ğŸ”§ Tune thresholds based on findings
6. ğŸ“ˆ Gradually increase sampling rate
7. ğŸ”’ Integrate with incident response workflow

## Support

For issues or questions:
- AgentCore Documentation: https://docs.aws.amazon.com/bedrock-agentcore/
- Evaluation Guide: https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/evaluations.html
- GitHub Issues: [Your repository]

## License

Apache 2.0 - See LICENSE file for details
